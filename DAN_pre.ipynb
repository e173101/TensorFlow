{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os \n",
    "import sys\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import uuid\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = 'F:\\\\datesets\\\\300W\\\\01_Indoor\\\\'\n",
    "output_dir = 'F:\\\\datesets\\\\300W\\\\01_Indoor_out\\\\'\n",
    "istrain = True\n",
    "repeat = 1 #??\n",
    "img_size = 112\n",
    "mirror_file = 'F:\\\\datesets\\\\Mirror68.txt'\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAffine(From, To):\n",
    "    FromMean = np.mean(From, axis=0)\n",
    "    ToMean = np.mean(To, axis=0)\n",
    "\n",
    "    FromCentralized = From - FromMean\n",
    "    ToCentralized = To - ToMean\n",
    "\n",
    "    FromVector = (FromCentralized).flatten()\n",
    "    ToVector = (ToCentralized).flatten()\n",
    "\n",
    "    DotResult = np.dot(FromVector, ToVector)\n",
    "    NormPow2 = np.linalg.norm(FromCentralized) ** 2\n",
    "\n",
    "    a = DotResult / NormPow2\n",
    "    b = np.sum(np.cross(FromCentralized, ToCentralized)) / NormPow2\n",
    "\n",
    "    R = np.array([[a, b], [-b, a]])\n",
    "    T = ToMean - np.dot(FromMean, R)\n",
    "\n",
    "    return R, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_data(imagepath, ptspath, is_train,mirror_array):\n",
    "    def makerotate(angle):\n",
    "        rad = angle * np.pi / 180.0\n",
    "        return np.array([[np.cos(rad), np.sin(rad)], [-np.sin(rad), np.cos(rad)]], dtype=np.float32)\n",
    "\n",
    "    srcpts = np.genfromtxt(ptspath.decode(), skip_header=3, skip_footer=1)\n",
    "    x, y = np.min(srcpts, axis=0).astype(np.int32)\n",
    "    w, h = np.ptp(srcpts, axis=0).astype(np.int32)\n",
    "    pts = (srcpts - [x, y]) / [w, h]\n",
    "\n",
    "    img = cv2.imread(imagepath.decode(), cv2.IMREAD_GRAYSCALE)\n",
    "    center = [0.5, 0.5]\n",
    "\n",
    "    if is_train:\n",
    "        pts = pts - center\n",
    "        pts = np.dot(pts, makerotate(np.random.normal(0, 20)))\n",
    "        pts = pts * np.random.normal(0.8, 0.05)\n",
    "        pts = pts + [np.random.normal(0, 0.05),\n",
    "                     np.random.normal(0, 0.05)] + center\n",
    "\n",
    "        pts = pts * img_size\n",
    "\n",
    "        R, T = getAffine(srcpts, pts)\n",
    "        M = np.zeros((2, 3), dtype=np.float32)\n",
    "        M[0:2, 0:2] = R.T\n",
    "        M[:, 2] = T\n",
    "        img = cv2.warpAffine(img, M, (img_size, img_size))\n",
    "\n",
    "        if any(mirror_array) and random.choice((True, False)):\n",
    "            pts[:,0] = img_size - 1 - pts[:,0]\n",
    "            pts = pts[mirror_array]\n",
    "            img = cv2.flip(img, 1)\n",
    "\n",
    "    else:\n",
    "        pts = pts - center\n",
    "        pts = pts * 0.8\n",
    "        pts = pts + center\n",
    "\n",
    "        pts = pts * img_size\n",
    "\n",
    "        R, T = getAffine(srcpts, pts)\n",
    "        M = np.zeros((2, 3), dtype=np.float32)\n",
    "        M[0:2, 0:2] = R.T\n",
    "        M[:, 2] = T\n",
    "        img = cv2.warpAffine(img, M, (img_size, img_size))\n",
    "\n",
    "\n",
    "    _,filename = os.path.split(imagepath.decode())\n",
    "    filename,_ = os.path.splitext(filename)\n",
    "\n",
    "    uid = str(uuid.uuid1())\n",
    "\n",
    "    cv2.circle(img, (int(pts[36][0]),int(pts[36][1])), 2, 255, 1) #left eye\n",
    "    cv2.circle(img, (int(pts[45][0]),int(pts[45][1])), 2, 255, 1) #right eye\n",
    "    cv2.circle(img, (int(pts[33][0]),int(pts[33][1])), 2, 255, 1) #nosise\n",
    "    cv2.circle(img, (int(pts[48][0]),int(pts[48][1])), 2, 255, 1)\n",
    "    cv2.circle(img, (int(pts[54][0]),int(pts[54][1])), 2, 255, 1)\n",
    "    cv2.imwrite(os.path.join(output_dir,filename + '@' + uid + '.png'),img)\n",
    "    np.savetxt(os.path.join(output_dir,filename + '@' + uid + '.ptv'),pts,delimiter=',')\n",
    "\n",
    "    return img,pts.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _input_fn(img, pts, is_train,mirror_array):\n",
    "    dataset_image = tf.data.Dataset.from_tensor_slices(img)\n",
    "    dataset_pts = tf.data.Dataset.from_tensor_slices(pts)\n",
    "    dataset = tf.data.Dataset.zip((dataset_image, dataset_pts))\n",
    "\n",
    "    dataset = dataset.prefetch(BATCH_SIZE)\n",
    "    dataset = dataset.repeat(repeat)\n",
    "    dataset = dataset.map(lambda imagepath, ptspath: tuple(tf.py_func(_load_data, [\n",
    "                          imagepath, ptspath, is_train,mirror_array], [tf.uint8,tf.float32])), num_parallel_calls=8)                     \n",
    "    dataset = dataset.prefetch(1)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_filenames(data_dir, listext):\n",
    "    imagelist = []\n",
    "    for ext in listext:\n",
    "        p = os.path.join(data_dir, ext)\n",
    "        imagelist.extend(glob.glob(p))\n",
    "\n",
    "    ptslist = []\n",
    "    for image in imagelist:\n",
    "        ptslist.append(os.path.splitext(image)[0] + \".pts\")\n",
    "\n",
    "    return imagelist, ptslist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end\n"
     ]
    }
   ],
   "source": [
    "#main\n",
    "imagenames, ptsnames = _get_filenames(input_dir, [\"*.jpg\", \"*.png\"])\n",
    "mirror_array = np.genfromtxt(mirror_file, dtype=int, delimiter=',') if mirror_file else np.zeros(1)\n",
    "\n",
    "dataset = _input_fn(imagenames,ptsnames,istrain,mirror_array)\n",
    "next_element = dataset.make_one_shot_iterator().get_next()\n",
    "\n",
    "img_list = []\n",
    "pts_list = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            img,pts = sess.run(next_element)\n",
    "            img_list.append(img)\n",
    "            pts_list.append(pts)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            img_list = np.stack(img_list)\n",
    "            pts_list = np.stack(pts_list)\n",
    " \n",
    "            mean_shape = np.mean(pts_list,axis=0)\n",
    "            imgs_mean = np.mean(img_list,axis=0)\n",
    "            imgs_std = np.std(img_list,axis=0)\n",
    " \n",
    "            np.savetxt(os.path.join(output_dir,'mean_shape.ptv'),mean_shape,delimiter=',')\n",
    "            np.savetxt(os.path.join(output_dir,'imgs_mean.ptv'),imgs_mean,delimiter=',')\n",
    "            np.savetxt(os.path.join(output_dir,'imgs_std.ptv'),imgs_std,delimiter=',')\n",
    " \n",
    "            print(\"end\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ptsnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
